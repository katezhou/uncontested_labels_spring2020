{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy.random import choice\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import scipy.stats as stats\n",
    "from IPython.display import display, HTML\n",
    "from statsmodels.stats.inter_rater import fleiss_kappa\n",
    "from statistics import mode\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset:\n",
    "    def __init__(self, data, label_name, name):\n",
    "        self.data = data\n",
    "        #The column name for the label in the dataset\n",
    "        self.label_name = label_name\n",
    "        #name of dataset\n",
    "        self.name = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trinarize data to be consistent to 2 or 3 categories\n",
    "def trinarize_misinfo(input):\n",
    "    if (input == \"Very high credibility\" or input == \"Somewhat high credibility\"):\n",
    "        return 1\n",
    "    elif (input == \"Medium credibility\"):\n",
    "        return 0\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trinarize_snli(input):\n",
    "    if(input == 'entailment'):\n",
    "        return 1\n",
    "    elif(input == 'neutral'):\n",
    "        return 0\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trinarize_sentiment(input):\n",
    "    if(int(input) > 0):\n",
    "        return 1\n",
    "    elif(int(input) == 0):\n",
    "        return 0\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading data and grouping annotations by tasks\n",
    "def get_data(data_file):\n",
    "    if (data_file == 'toxicity'):\n",
    "        data = pd.read_csv(\"data/TOXICITY_toxicity_individual_annotations.csv\")\n",
    "        grouped = data.groupby(\"id\")[['id', 'toxic']]\n",
    "    \n",
    "    if (data_file == 'misinfo'):\n",
    "        data = pd.read_csv(\"data/MISINFO_misinfo_credco_2019_study_cplusj_2020_subset.csv\")\n",
    "        annotators = pd.read_csv(\"data/MISINFO_misinfo_credco_study_2019_crowd_annotators_simple.csv\")\n",
    "        \n",
    "        #combine data with annotators\n",
    "        data = data[data['annotator'].isin(annotators[annotators['pool']=='Upwork']['annotator_id'].values)]\n",
    "        \n",
    "        #one annotator that had 26 labels insteaad of 25\n",
    "        data = data[data['annotator'] != 'CredCo-3AA.33']\n",
    "        data = data[['report_title', 'task_1_answer']]\n",
    "        data['task_1_answer'] = [trinarize_misinfo(x) for x in data['task_1_answer']]\n",
    "        grouped = data.groupby(\"report_title\")\n",
    "    \n",
    "    if (data_file == 'pg13'):\n",
    "        data = pd.read_csv(\"data/PG13_labels.txt\", sep='\\t', header=None)\n",
    "        #keep only annotations with at least ten labels\n",
    "        filtered = data.groupby(1)[1].filter(lambda x: len(x) >= 10)\n",
    "        grouped = data[data[1].isin(filtered)].groupby(1)\n",
    "    \n",
    "    if (data_file == 'bots'):\n",
    "        data = pd.read_csv(\"data/BOTS_crowdflower_results_detailed.csv\")[['crowdflower_id', 'class']]\n",
    "        #keep only annotations with at least three labels\n",
    "        filtered = data.groupby('crowdflower_id')['crowdflower_id'].filter(lambda x: len(x) >= 3)\n",
    "        grouped = data[data['crowdflower_id'].isin(filtered)].groupby('crowdflower_id')\n",
    "\n",
    "    if (data_file == 'snli'):\n",
    "        # snli check\n",
    "        # dynamic worker routing\n",
    "        data = pd.read_json(\"data/SNLI_snli_1.0_train.jsonl\", lines=True)\n",
    "        labels = []\n",
    "        for name, row in data.iterrows():\n",
    "        #keep only annotations with at least five labels\n",
    "            if len(row[\"annotator_labels\"]) >= 5:\n",
    "                for label in row[\"annotator_labels\"]:\n",
    "                    labels.append({\"idx\": name, \"label\": label})\n",
    "        data = pd.DataFrame(labels)\n",
    "        data['label'] = [trinarize_snli(x) for x in data[['label']].values]\n",
    "        data = data[['idx', 'label']]\n",
    "        grouped = data.groupby(\"idx\")\n",
    "        \n",
    "    if (data_file == 'sentiment'):\n",
    "        data = pd.read_table(\"data/SENTIMENT_cred_event_TurkRatings.data\", sep='\\t')\n",
    "        labels = []\n",
    "        for name, row in data.iterrows():\n",
    "            #keep only annotations with at least thirty labels\n",
    "            if len(row[\"Cred_Ratings\"]) >= 30:\n",
    "                row = row['Cred_Ratings'][1:-1].split(\",\")\n",
    "                for label in row:\n",
    "                    labels.append({\"idx\": name, \"label\": label})\n",
    "        data = pd.DataFrame(labels)\n",
    "        data['label'] = [trinarize_sentiment(int(x[0].strip(\"\\', \\\"\"))) for x in data[['label']].values]\n",
    "        data = data[['idx', 'label']]\n",
    "        grouped = data.groupby(\"idx\")\n",
    "    \n",
    "    if (data_file == 'wsd'):\n",
    "        data = pd.read_csv(\"data/WSD_wsd.standardized.tsv\", sep='\\t')\n",
    "        grouped = data.groupby(\"orig_id\")\n",
    "        \n",
    "    return grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find a way to generate samples and finding the majority from each sample\n",
    "def find_majority(values, sample_size):\n",
    "    random = choice(values, sample_size * 2, replace=True)\n",
    "    sample1 = Counter(random[:sample_size]).most_common(sample_size)\n",
    "    sample2 = Counter(random[sample_size:]).most_common(sample_size)\n",
    "    majority_1 = sample1[0][0]\n",
    "    majority_2 = sample2[0][0]  \n",
    "    if ((len(sample1) > 1 and sample1[0][1] == sample1[1][1])): #no majority\n",
    "        majority_1 = 'NM'\n",
    "    if (len(sample2) > 1 and sample2[0][1] == sample2[1][1]): #no majority\n",
    "        majority_2 = 'NM'\n",
    "    return sample1, sample2, majority_1, majority_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create parellel datasets of size 1, 3, 5, 7, 9\n",
    "#and compare flip rate between the parallel datasets\n",
    "#Resample 100 times and take the average of these iterations\n",
    "def resample_flipping(data_object):\n",
    "    for sample_size in [1, 3, 5, 7, 9]:\n",
    "        flip_count = 0\n",
    "        for iterations in tqdm(range(0, 100)):\n",
    "            for name, group in data_object.data:\n",
    "                sample1, sample2, majority_1, majority_2 = find_majority(group[data_object.label_name].values, sample_size)\n",
    "                if (majority_1 != majority_2):\n",
    "                    flip_count += 1\n",
    "\n",
    "        print('sample size', sample_size)\n",
    "        print(\"flip average percent\", round(flip_count/len(data_object.data), 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a parallel dataset, how many of these labels flip?\n",
    "#Create another parallel dataset, how many of original labels flipped at least once?\n",
    "#Repeat this process for up to 5 parallel datasets\n",
    "#Repeat this process 100 times and take the average number of flips for 1, 2, 3, 4, 5 parallele datasets\n",
    "def population_level(data_object):\n",
    "    sample_size = 5\n",
    "    percent_map = {}\n",
    "    for x in tqdm(range(0, 100)):\n",
    "        flipped_labels = {}\n",
    "        label_count = {}\n",
    "\n",
    "        for iteration in range(1, 6):\n",
    "            temp = []\n",
    "            for name, group in data_object.data:\n",
    "                values = group[data_object.label_name].values\n",
    "                #find the gold label for the data point\n",
    "                actual_label = Counter(values).most_common(len(values))[0][0]\n",
    "                #keep track of how many gold labels there are\n",
    "\n",
    "                if (actual_label not in label_count):\n",
    "                    label_count[actual_label] = set()\n",
    "                    flipped_labels[actual_label] = set()\n",
    "                \n",
    "                label_count[actual_label].add(name) \n",
    "                #keep track of how many labels in this category flipped\n",
    "                sample1, sample2, majority_1, majority_2 = find_majority(group[data_object.label_name].values, sample_size)\n",
    "                if (majority_1 != majority_2):\n",
    "                    flipped_labels[actual_label].add(name)\n",
    "\n",
    "            for actual_label in label_count:\n",
    "                percent = round(len(flipped_labels[actual_label])/len(label_count[actual_label]), 2)\n",
    "                key = \"iteration: \" + str(iteration) + \" label:\" + str(actual_label)\n",
    "                percent_map[key] = round(percent_map.get(key, 0) + percent, 2)\n",
    "    for x in percent_map:\n",
    "        print(x, percent_map[x])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess data for each of the data to calculate\n",
    "#fleiss kappa scores\n",
    "def calculate_fleiss_kappa(data_object):\n",
    "    result = []\n",
    "    if (data_object.name == 'pg13'):        \n",
    "        map = {'G':0, 'P':1, 'X':2, 'R':3}\n",
    "        for i, x in data_object.data:\n",
    "            #need at least five samples\n",
    "            #create a sample out of 5\n",
    "            if (len(list(x[data_object.label_name].values)) >= 5):\n",
    "                counts = Counter(random.sample(list(x[data_object.label_name].values), 5))\n",
    "                temp = [0] * 4\n",
    "                for y in counts:\n",
    "                    temp[map[y]] = counts[y]\n",
    "                result.append(temp)\n",
    "            \n",
    "    if (data_object.name == 'misinfo' or data_object.name == 'snli'):        \n",
    "        for i, x in data_object.data:\n",
    "            counts = Counter(x[data_object.label_name].values)\n",
    "            temp = [0] * 3\n",
    "            for y in counts:\n",
    "                temp[y + 1] = counts[y]\n",
    "            result.append(temp)\n",
    "    \n",
    "    if (data_object.name == 'wsd'):        \n",
    "        for i, x in data_object.data:\n",
    "            counts = Counter(x[data_object.label_name].values)\n",
    "            temp = [0] * 3\n",
    "            for y in counts:\n",
    "                temp[y - 1] = counts[y]\n",
    "            result.append(temp)\n",
    "    \n",
    "    if (data_object.name == 'sentiment'):\n",
    "        for i, x in data_object.data:\n",
    "            if (len(list(x[data_object.label_name].values)) >= 30):\n",
    "                counts = Counter(x[data_object.label_name].values)\n",
    "                temp = [0] * 3\n",
    "                for y in counts:\n",
    "                    temp[y + 1] = counts[y]\n",
    "                result.append(temp)\n",
    "    \n",
    "    if (data_object.name =='toxic'):\n",
    "        for name, group in tqdm(data_object.data):\n",
    "            subsample = group.sample(5, replace = True)\n",
    "            temp = subsample['toxic'].values\n",
    "            result.append(temp)\n",
    "\n",
    "        result = pd.DataFrame(result)\n",
    "        result['toxic'] = result.sum(axis=1)\n",
    "        result['non_toxic'] = 5 - result['toxic']\n",
    "        result = result[['toxic', 'non_toxic']].values\n",
    "    \n",
    "    if (data_object.name == 'bots'):        \n",
    "        map = {'genuine':0, 'spambot':1, 'unable':2}\n",
    "        for i, x in data_object.data:\n",
    "            if (len(list(x[data_object.label_name].values)) >= 3):\n",
    "                counts = Counter(x[data_object.label_name].values)\n",
    "                temp = [0] * 3\n",
    "                for y in counts:\n",
    "                    temp[map[y]] = counts[y]\n",
    "                result.append(temp)\n",
    "    print(\"fleiss kappa score: \", fleiss_kappa(result, method='fleiss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create parallel datasets\n",
    "def calculate_class_difference_helper(data_object):\n",
    "    sample_size_to_resampled_dataset = {}\n",
    "\n",
    "    for sample_size in [5, 7, 9]:\n",
    "        resampled_datasets = [[], [],[], []]\n",
    "        for iterations in tqdm(range(0, 100)):\n",
    "            for name, group in data_object.data:\n",
    "                sample1, sample2, majority_1, majority_2 = find_majority(group[data_object.label_name].values, sample_size)\n",
    "\n",
    "                resampled_datasets[0].append(name)\n",
    "                resampled_datasets[1].append(majority_1)\n",
    "                resampled_datasets[2].append(majority_2)\n",
    "                resampled_datasets[3].append(0) # assume no difference\n",
    "\n",
    "                if (majority_1 != majority_2):\n",
    "                    # in case sample2 didn't have any votes for the majority class from sample1\n",
    "                    resampled_datasets[3].append(abs(sample1[0][1]))\n",
    "                    for x in sample2:\n",
    "                        if (x[0] == majority_1):\n",
    "                            resampled_datasets[3].append(abs(sample1[0][1] - x[1]))\n",
    "        sample_size_to_resampled_dataset[sample_size] = resampled_datasets\n",
    "    return sample_size_to_resampled_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#across the parallel datasets, calculate how large of a difference exists\n",
    "#between contested labels\n",
    "def calculate_difference_of_flip(sample_size_to_resampled_dataset):\n",
    "    for sample_size in sample_size_to_resampled_dataset:\n",
    "        print(\"sample size\", sample_size)\n",
    "        resampled_dataset = sample_size_to_resampled_dataset[sample_size]\n",
    "        results = pd.DataFrame(resampled_dataset).transpose()\n",
    "        \n",
    "        #get rid of no modes\n",
    "        results = results[results[1] != 'NM']\n",
    "        results = results[results[2] != 'NM']\n",
    "        results[3] = pd.to_numeric(results[3])\n",
    "        \n",
    "        print(\"mean\")\n",
    "        print(round(results[results[1] != results[2]][[3]].mean().values[0], 2))\n",
    "        print(\"std\")\n",
    "        print(round(results[results[1] != results[2]][[3]].std().values[0], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Across the parallel datasets, calculate the flip rate for each class\n",
    "#given sample size of 5\n",
    "def calculate_flips_per_class(sample_size_to_resampled_dataset):\n",
    "    resampled_dataset = sample_size_to_resampled_dataset[5]\n",
    "    resampled_dataset = pd.DataFrame(resampled_dataset).transpose()\n",
    "    \n",
    "    grouped = resampled_dataset[resampled_dataset[1] != resampled_dataset[2]].groupby([1]).count()\n",
    "    print(\"flip per class\")\n",
    "#     display(grouped)\n",
    "    print(\"total count\")\n",
    "    counts = resampled_dataset.groupby([1]).count()\n",
    "#     display(counts)\n",
    "    print(round(grouped[0]/counts[0],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'data/TOXICITY_toxicity_individual_annotations.csv' does not exist: b'data/TOXICITY_toxicity_individual_annotations.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-bef602912c4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Create all the data objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtoxicity_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"toxicity\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'toxic'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'toxic'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmisinfo_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"misinfo\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'task_1_answer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'misinfo'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpg13_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pg13\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pg13'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbots_object\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mdataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bots\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'class'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bots'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-1a432e34f577>\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(data_file)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'toxicity'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/TOXICITY_toxicity_individual_annotations.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mgrouped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'toxic'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nlp/anaconda/main/anaconda3/envs/katezhou/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nlp/anaconda/main/anaconda3/envs/katezhou/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nlp/anaconda/main/anaconda3/envs/katezhou/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nlp/anaconda/main/anaconda3/envs/katezhou/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nlp/anaconda/main/anaconda3/envs/katezhou/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'data/TOXICITY_toxicity_individual_annotations.csv' does not exist: b'data/TOXICITY_toxicity_individual_annotations.csv'"
     ]
    }
   ],
   "source": [
    "#Create all the data objects\n",
    "toxicity_object = dataset(get_data(\"toxicity\"), 'toxic', 'toxic')\n",
    "misinfo_object = dataset(get_data(\"misinfo\"), 'task_1_answer', 'misinfo')\n",
    "pg13_object = dataset(get_data(\"pg13\"), 2, 'pg13')\n",
    "bots_object =  dataset(get_data(\"bots\"), 'class', 'bots')\n",
    "snli_object = dataset(get_data(\"snli\"), 'label', 'snli')\n",
    "sentiment_object = dataset(get_data(\"sentiment\"), 'label', 'sentiment')\n",
    "wsd_object = dataset(get_data(\"wsd\"), 'response', 'wsd')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run any of the tests\n",
    "def run_test(datasets, test, helper=False):\n",
    "    for dataset in datasets:\n",
    "        print('------------------------')\n",
    "        print(dataset.name)\n",
    "        if (helper):\n",
    "            sample_size_to_resampled_dataset = calculate_class_difference_helper(dataset)\n",
    "            calculate_difference_of_flip(sample_size_to_resampled_dataset)\n",
    "            calculate_flips_per_class(sample_size_to_resampled_dataset)\n",
    "        else:\n",
    "            test(dataset)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_datasets = [toxicity_object, misinfo_object, pg13_object, bots_object, snli_object, sentiment_object, wsd_object]\n",
    "#test 1 - Resample Flip\n",
    "# run_test(list_of_datasets, resample_data)\n",
    "# #test 2 - Population Level\n",
    "# run_test(list_of_datasets, population_level)\n",
    "# #test 3 - Fleiss Kappa\n",
    "run_test(list_of_datasets, calculate_fleiss_kappa)\n",
    "# Helper + test 4, test 5 - Difference in Flip, Flips across Classes\n",
    "# run_test(list_of_datasets, None, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
